# LaPa-Dataset
## Introduction
we develop a high-efficiency framework for pixel-level face parsing annotating and construct a new large-scale **La**ndmark guided face **Pa**rsing dataset (LaPa). It consists of more than 22,000 facial images with abundant variations in expression, pose and occlusion, and each image of LaPa is provided with a 11-category pixel-level label map and 106-point landmarks.

<img src="https://github.com/lucia123/lapa-dataset/blob/master/sample.png" width="600" alt="picture"/>

<center>Fig. 1: Annotation examples of the proposed LaPa dataset.</center>

## Download
[Google Drive](https://drive.google.com/open?id=1EtyCtiQZt2Y5qrb-0YxRxaVLpVcgCOQV)

[Baidu](https://pan.baidu.com/s/1wwQAdLRLo6WwF03j8Jo4RA) code: ewd2

## Citation
If you use our datasets, please cite the following paper:

[A New Dataset and Boundary-Attention Semantic Segmentation for Face Parsing.](https://www.aaai.org/Papers/AAAI/2020GB/AAAI-LiuY.6557.pdf) Yinglu Liu, Hailin Shi, Hao Shen, Yue Si, Xiaobo Wang, Tao Mei. In AAAI, 2020.


## License
This LaPa Dataset is made freely available to academic and non-academic entities for non-commercial purposes such as academic research, teaching, scientific publications, or personal experimentation. Permission is granted to use the data given that you agree to our license terms.
